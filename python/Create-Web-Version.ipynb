{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import numpy as np\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor\n",
    "from arcgis.features import GeoSeriesAccessor\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.pivot_table(df, values='a', index='b', columns='c', aggfunc='sum', fill_value=0)\n",
    "# pd.DataFrame.spatial.from_featureclass(???)  \n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track run time\n",
    "start = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA values in Spatially enabled dataframes (ignores SHAPE column)\n",
    "def fill_na_sedf(df_with_shape_column, fill_value=0):\n",
    "    if 'SHAPE' in list(df_with_shape_column.columns):\n",
    "        df = df_with_shape_column.copy()\n",
    "        shape_column = df['SHAPE'].copy()\n",
    "        del df['SHAPE']\n",
    "        return df.fillna(fill_value).merge(shape_column,left_index=True, right_index=True, how='inner')\n",
    "    else:\n",
    "        raise Exception(\"Dataframe does not include 'SHAPE' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Outputs'):\n",
    "    os.makedirs('Outputs')\n",
    "    \n",
    "outputs = ['.\\\\Outputs', \"scratch.gdb\", 'hui_for_web2.gdb']\n",
    "gdb = os.path.join(outputs[0], outputs[1])\n",
    "gdb2 = os.path.join(outputs[0], outputs[2])\n",
    "\n",
    "if not arcpy.Exists(gdb):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[1])\n",
    "\n",
    "if not arcpy.Exists(gdb2):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hui= r'.\\inputs\\housing_unit_inventory_2022.gdb\\housing_unit_inventory_2022'\n",
    "# hui_wfrc = r\".\\inputs\\WFRC_Housing_Unit_Inventory_20240725.gdb\\housing_unit_inventory_2022\"\n",
    "hui_wfrc = r\"E:\\\\Tasks\\\\Housing_Unit_Inventory_Update\\\\2024-WFRC-Update\\\\Outputs\\\\results.gdb\\\\wfrc_hui_2024\"\n",
    "hui_mag = r'.\\inputs\\MAG_Housing_Unit_Inventory_20250410.gdb\\housing_unit_inventory'\n",
    "hui_box_elder = r\".\\inputs\\WFRC_Housing_Unit_Inventory_20240725.gdb\\housing_unit_inventory_box_elder_2020_UPDATED\"\n",
    "hui_tooele = r\".\\inputs\\housing_unit_inventory_tooele_20241007.gdb\\housing_unit_inventory_2024\"\n",
    "hui_morgan = r\".\\inputs\\Morgan_Housing_Unit_Inventory_20241031.gdb\\housing_unit_inventory_2024\"\n",
    "t = r'.\\inputs\\transit_stations_and_interchanges.shp'\n",
    "t_lyr = arcpy.MakeFeatureLayer_management(t, 't_lyr')\n",
    "parks = r\".\\inputs\\wcv_parks.shp\"\n",
    "trails = r\".\\inputs\\TrailsAndPathways_WFRCMAG.shp\"\n",
    "trails_lyr = arcpy.MakeFeatureLayer_management(trails, 'trails_lyr')\n",
    "# centers = r\".\\inputs\\Boundaries.gdb\\Centers\"\n",
    "centers = arcpy.MakeFeatureLayer_management('https://services1.arcgis.com/taguadKoI1XFwivx/arcgis/rest/services/WCV_Centers_and_Regional_Land_Uses/FeatureServer/0', 'centers_lyr')\n",
    "cities = r\".\\inputs\\Boundaries.gdb\\Cities\"\n",
    "counties = r\".\\inputs\\Boundaries.gdb\\Counties\"\n",
    "subregions = r'.\\inputs\\Boundaries.gdb\\Subregions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hui_ugrc = 'https://services1.arcgis.com/99lidPhWCzftIe9K/ArcGIS/rest/services/HousingUnitInventory/FeatureServer/0'\n",
    "hui_washington_lyr = arcpy.management.MakeFeatureLayer(hui_ugrc, \"hui_washington_lyr\", where_clause=\"\"\"COUNTY = 'Washington'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for the \"Vintage\" Attribute\n",
    "vintages = {\n",
    "    \n",
    "    'Davis':2024,\n",
    "    'Weber':2024,\n",
    "    'Box Elder (MPO Area)':2020,\n",
    "    'Utah':2024,\n",
    "    'Tooele':2024,\n",
    "    'Morgan':2024,\n",
    "    'Salt Lake':2024,\n",
    "    'Washington':2022\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable this if proximity has recently been run\n",
    "rerun_proximity_functions = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Thursday, May 22, 2025 4:57:18 PM<br>Succeeded at Thursday, May 22, 2025 4:57:47 PM (Elapsed Time: 28.58 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\scratch.gdb\\\\simplified_hui'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge housing datasets, simplify and recalculate UNIT_ID (some units may disappear)\n",
    "hui_merged = arcpy.management.Merge([hui_wfrc, hui_mag, hui_box_elder, hui_tooele, hui_morgan, hui_washington_lyr], os.path.join(gdb, 'merged_hui')) \n",
    "# hui_merged = arcpy.management.Merge([hui_wfrc, hui_mag, hui_box_elder, hui_tooele, hui_morgan, hui_washington_lyr], os.path.join(gdb, 'merged_hui')) \n",
    "hui = arcpy.cartography.SimplifyPolygon(hui_merged, os.path.join(gdb, 'simplified_hui'), \"POINT_REMOVE\", 2.5)\n",
    "arcpy.CalculateField_management(hui,\"UNIT_ID\",'!OBJECTID!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to summarize get the center name\n",
    "target_features = hui\n",
    "join_features = centers\n",
    "output_features = os.path.join(gdb, \"_00_hui_center_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "fields = ['CenterName']\n",
    "for f in fields:\n",
    "\n",
    "# field\n",
    "    fieldindex = fieldmappings.findFieldMapIndex(f)\n",
    "    fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "    fieldmap.mergeRule = 'first'\n",
    "    fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "center_sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_COMMON\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")\n",
    "\n",
    "center_sj_df = pd.DataFrame.spatial.from_featureclass(center_sj[0])\n",
    "center_sj_df = center_sj_df[['UNIT_ID', 'CenterName', 'CenterType']].copy()\n",
    "center_sj_df.columns = ['UNIT_ID', 'CENTER', 'CENTERTYPE']\n",
    "center_sj_df['UNIT_ID'] = center_sj_df['UNIT_ID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to summarize get the center name\n",
    "target_features = hui\n",
    "join_features = cities\n",
    "output_features = os.path.join(gdb, \"_00_hui_city_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "fields = ['NAME']\n",
    "for f in fields:\n",
    "\n",
    "# field\n",
    "    fieldindex = fieldmappings.findFieldMapIndex(f)\n",
    "    fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "    fieldmap.mergeRule = 'first'\n",
    "    fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "city_sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_COMMON\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")\n",
    "\n",
    "city_sj_df = pd.DataFrame.spatial.from_featureclass(city_sj[0])\n",
    "city_sj_df = city_sj_df[['UNIT_ID', 'NAME']].copy()\n",
    "city_sj_df.columns = ['UNIT_ID', 'CITY']\n",
    "city_sj_df['UNIT_ID'] = city_sj_df['UNIT_ID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to summarize get the subregion name\n",
    "target_features = hui\n",
    "join_features = subregions\n",
    "output_features = os.path.join(gdb, \"_00_hui_subregion_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "fields = ['NewSA']\n",
    "for f in fields:\n",
    "\n",
    "# field\n",
    "    fieldindex = fieldmappings.findFieldMapIndex(f)\n",
    "    fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "    fieldmap.mergeRule = 'first'\n",
    "    fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "subregion_sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_COMMON\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")\n",
    "\n",
    "subregion_sj_df = pd.DataFrame.spatial.from_featureclass(subregion_sj[0])\n",
    "subregion_sj_df = subregion_sj_df[['UNIT_ID', 'NewSA']].copy()\n",
    "subregion_sj_df.columns = ['UNIT_ID', 'SUBCOUNTY']\n",
    "subregion_sj_df['UNIT_ID'] = subregion_sj_df['UNIT_ID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT_ID</th>\n",
       "      <th>SUBCOUNTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>North Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>North Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>North Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>North Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>North Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611862</th>\n",
       "      <td>618247</td>\n",
       "      <td>Box Elder (WFRC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611863</th>\n",
       "      <td>618248</td>\n",
       "      <td>Box Elder (WFRC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611864</th>\n",
       "      <td>618251</td>\n",
       "      <td>Box Elder (WFRC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611865</th>\n",
       "      <td>618252</td>\n",
       "      <td>Box Elder (WFRC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611866</th>\n",
       "      <td>618253</td>\n",
       "      <td>Box Elder (WFRC)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>611867 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UNIT_ID               SUBCOUNTY\n",
       "0             1  North Salt Lake County\n",
       "1             2  North Salt Lake County\n",
       "2             3  North Salt Lake County\n",
       "3             4  North Salt Lake County\n",
       "4             5  North Salt Lake County\n",
       "...         ...                     ...\n",
       "611862   618247        Box Elder (WFRC)\n",
       "611863   618248        Box Elder (WFRC)\n",
       "611864   618251        Box Elder (WFRC)\n",
       "611865   618252        Box Elder (WFRC)\n",
       "611866   618253        Box Elder (WFRC)\n",
       "\n",
       "[611867 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subregion_sj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to summarize get the center name\n",
    "target_features = hui\n",
    "join_features = counties\n",
    "output_features = os.path.join(gdb, \"_00_hui_county_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "fields = ['NAME']\n",
    "for f in fields:\n",
    "\n",
    "# field\n",
    "    fieldindex = fieldmappings.findFieldMapIndex(f)\n",
    "    fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "    fieldmap.mergeRule = 'first'\n",
    "    fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "county_sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_COMMON\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")\n",
    "\n",
    "county_sj_df = pd.DataFrame.spatial.from_featureclass(county_sj[0])\n",
    "county_sj_df = county_sj_df[['UNIT_ID', 'NAME']].copy()\n",
    "county_sj_df.columns = ['UNIT_ID', 'COUNTY']\n",
    "county_sj_df['UNIT_ID'] = county_sj_df['UNIT_ID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'parks'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=parks, method='GEODESIC')\n",
    "    df_parks = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_parks = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_parks['UNIT_ID'] = df_parks['UNIT_ID'].astype('Int64')\n",
    "# df_parks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'trails'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(trails_lyr, 'NEW_SELECTION', \"\"\"Status IN ('EXISTING', 'Existing', 'Current')\"\"\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=trails_lyr, method='GEODESIC')\n",
    "    df_trails = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_trails = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_trails['UNIT_ID'] = df_trails['UNIT_ID'].astype('Int64')\n",
    "# df_trails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'frontrunner'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Commuter Rail Station' AND Status = 'Current'\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_fr = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_fr = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_fr['UNIT_ID'] = df_fr['UNIT_ID'].astype('Int64')\n",
    "# df_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lightrail'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Light Rail Station' AND Status = 'Current'\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_lr = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_lr = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_lr['UNIT_ID'] = df_lr['UNIT_ID'].astype('Int64')\n",
    "# df_lr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'brt'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'BRT Stop' And (Status = 'Current' Or Status IS NULL)\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_brt = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_brt = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_brt['UNIT_ID'] = df_brt['UNIT_ID'].astype('Int64')\n",
    "# df_brt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'fwyexit'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Interchange' AND Status = 'Current'\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_fwy = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_fwy = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_fwy['UNIT_ID'] = df_fwy['UNIT_ID'].astype('Int64')\n",
    "# df_fwy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert distance from meters to miles\n",
    "df_fr['DIST_FR'] = df_fr['NEAR_DIST']*.000621371\n",
    "df_lr['DIST_LR'] = df_lr['NEAR_DIST']*.000621371\n",
    "df_brt['DIST_BRT'] = df_brt['NEAR_DIST']*.000621371\n",
    "df_fwy['DIST_FWYE'] = df_fwy['NEAR_DIST']*.000621371\n",
    "df_parks['DIST_PARK'] = df_parks['NEAR_DIST']*.000621371\n",
    "df_trails['DIST_TRAIL'] = df_trails['NEAR_DIST']*.000621371\n",
    "\n",
    "df_fr['DIST_FR'] = round(df_fr['DIST_FR'], 2)\n",
    "df_lr['DIST_LR'] = round(df_lr['DIST_LR'], 2)\n",
    "df_brt['DIST_BRT'] = round(df_brt['DIST_BRT'], 2)\n",
    "df_fwy['DIST_FWYE'] = round(df_fwy['DIST_FWYE'], 2)\n",
    "df_parks['DIST_PARK'] = round(df_parks['DIST_PARK'], 2)\n",
    "df_trails['DIST_TRAIL'] = round(df_trails['DIST_TRAIL'], 2)\n",
    "\n",
    "df_fr = df_fr[['UNIT_ID', 'DIST_FR']].copy()\n",
    "df_lr = df_lr[['UNIT_ID', 'DIST_LR']].copy()\n",
    "df_brt = df_brt[['UNIT_ID', 'DIST_BRT']].copy()\n",
    "df_fwy = df_fwy [['UNIT_ID', 'DIST_FWYE']].copy()\n",
    "df_parks = df_parks[['UNIT_ID', 'DIST_PARK']].copy()\n",
    "df_trails = df_trails[['UNIT_ID', 'DIST_TRAIL']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "hui_df = pd.DataFrame.spatial.from_featureclass(hui[0])\n",
    "\n",
    "# these are recomputed\n",
    "del hui_df['CITY']\n",
    "del hui_df['COUNTY']\n",
    "del hui_df['SUBCOUNTY']\n",
    "\n",
    "# set cutoff year built\n",
    "cutoff_year = 2026\n",
    "hui_df = hui_df[(hui_df['APX_BLT_YR'] < cutoff_year) | (hui_df['APX_BLT_YR'].isna())].copy()\n",
    "\n",
    "# Remove MAG EVAL_DATE field\n",
    "del hui_df['EVAL_DATE']\n",
    "\n",
    "# delete fields added from simplify polygon tool\n",
    "del hui_df['InPoly_FID']\n",
    "del hui_df['MaxSimpTol']\n",
    "del hui_df['MinSimpTol']\n",
    "\n",
    "hui_df = (hui_df.merge(city_sj_df, on='UNIT_ID', how='left')\n",
    "                .merge(subregion_sj_df, on='UNIT_ID', how='left') \n",
    "                .merge(county_sj_df, on='UNIT_ID', how='left') \n",
    "                .merge(center_sj_df, on='UNIT_ID', how='left') \n",
    "                .merge(df_fr, on='UNIT_ID', how='left') \n",
    "                .merge(df_lr, on='UNIT_ID', how='left')  \n",
    "                .merge(df_brt, on='UNIT_ID', how='left')\n",
    "                .merge(df_fwy, on='UNIT_ID', how='left')\n",
    "                .merge(df_parks, on='UNIT_ID', how='left')\n",
    "                .merge(df_trails, on='UNIT_ID', how='left')) \n",
    "\n",
    "# clear memory\n",
    "# for df in [sj_df, df_fr, df_lr, df_brt, df_fwy, df_parks, df_trails]: del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the date field for timeslider\n",
    "hui_df['APX_BLT_YR'] = hui_df['APX_BLT_YR'].astype('Int64')\n",
    "hui_df.loc[hui_df['APX_BLT_YR'].isna() == True, 'APX_BLT_YR'] = 0\n",
    "hui_df['BLT_YR2'] = pd.to_datetime(hui_df['APX_BLT_YR'].astype(str) + '-01-02', errors='coerce')\n",
    "hui_df.loc[hui_df['APX_BLT_YR'] == 0, 'APX_BLT_YR'] = np.nan\n",
    "# hui_df.loc[hui_df['APX_BLT_YR'] > 0, 'BLT_YR2'] = pd.to_datetime(hui_df['APX_BLT_YR'], format='%Y',  errors='coerce')\n",
    "\n",
    "# alter the built decade attribute\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1840) & (hui_df['APX_BLT_YR'] < 1850), 'BLT_DECADE'] = \"1840\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1850) & (hui_df['APX_BLT_YR'] < 1860), 'BLT_DECADE'] = \"1850\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1860) & (hui_df['APX_BLT_YR'] < 1870), 'BLT_DECADE'] = \"1860\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1870) & (hui_df['APX_BLT_YR'] < 1880), 'BLT_DECADE'] = \"1870\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1880) & (hui_df['APX_BLT_YR'] < 1890), 'BLT_DECADE'] = \"1880\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1890) & (hui_df['APX_BLT_YR'] < 1900), 'BLT_DECADE'] = \"1890\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1900) & (hui_df['APX_BLT_YR'] < 1910), 'BLT_DECADE'] = \"1900\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1910) & (hui_df['APX_BLT_YR'] < 1920), 'BLT_DECADE'] = \"1910\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1920) & (hui_df['APX_BLT_YR'] < 1930), 'BLT_DECADE'] = \"1920\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1930) & (hui_df['APX_BLT_YR'] < 1940), 'BLT_DECADE'] = \"1930\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1940) & (hui_df['APX_BLT_YR'] < 1950), 'BLT_DECADE'] = \"1940\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1950) & (hui_df['APX_BLT_YR'] < 1960), 'BLT_DECADE'] = \"1950\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1960) & (hui_df['APX_BLT_YR'] < 1970), 'BLT_DECADE'] = \"1960\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1970) & (hui_df['APX_BLT_YR'] < 1980), 'BLT_DECADE'] = \"1970\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1980) & (hui_df['APX_BLT_YR'] < 1990), 'BLT_DECADE'] = \"1980\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1990) & (hui_df['APX_BLT_YR'] < 2000), 'BLT_DECADE'] = \"1990\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 2000) & (hui_df['APX_BLT_YR'] < 2010), 'BLT_DECADE'] = \"2000\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 2010) & (hui_df['APX_BLT_YR'] < 2020), 'BLT_DECADE'] = \"2010\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 2020) & (hui_df['APX_BLT_YR'] < 2030), 'BLT_DECADE'] = \"2020\"\n",
    "hui_df.loc[hui_df['BLT_DECADE'].isin(['1840', '1850', '1860', '1870', '1880', '1890']) == True, 'BLT_DECADE'] = '1840-1890'\n",
    "hui_df.loc[hui_df['BLT_DECADE'].isin(['1900', '1910', '1920', '1930', '1940', '1950']) == True, 'BLT_DECADE'] = '1900-1950'\n",
    "\n",
    "# confirm type classification\n",
    "hui_df.loc[hui_df['SUBTYPE'].isin(['single_family', 'single_family_adu']) == True, 'TYPE'] = 'single_family'\n",
    "hui_df.loc[hui_df['SUBTYPE'].isin(['single_family', 'single_family_adu']) == False, 'TYPE'] = 'multi_family'\n",
    "\n",
    "# assign vintage from dictionary\n",
    "hui_df['VINTAGE'] = hui_df['COUNTY'].map(vintages)\n",
    "\n",
    "# area and dua\n",
    "gsa = GeoSeriesAccessor(hui_df['SHAPE'])  \n",
    "hui_df['ACRES'] = gsa.area  # KNOW YOUR UNITS\n",
    "hui_df['ACRES'] = hui_df['ACRES'] * 0.000247105\n",
    "hui_df['ACRES'] = hui_df['ACRES'].astype('Float64').round(2)\n",
    "del gsa\n",
    "\n",
    "hui_df['DUA'] = round(hui_df['UNIT_COUNT'] / hui_df['ACRES'], 2)\n",
    "hui_df['DUA'] = hui_df['DUA'].astype('Float64').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695241, 26)\n"
     ]
    }
   ],
   "source": [
    "print(hui_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID               Int64\n",
      "TYPE          string[python]\n",
      "SUBTYPE       string[python]\n",
      "IS_OUG                 Int32\n",
      "UNIT_COUNT             int32\n",
      "DUA                  Float64\n",
      "ACRES                Float64\n",
      "TOT_BD_FT2             Int32\n",
      "TOT_VALUE            Float64\n",
      "APX_BLT_YR             Int32\n",
      "BLT_DECADE    string[python]\n",
      "BLT_YR2       datetime64[ns]\n",
      "VINTAGE              float64\n",
      "UNIT_ID                int32\n",
      "SHAPE               geometry\n",
      "CITY          string[python]\n",
      "SUBCOUNTY     string[python]\n",
      "COUNTY        string[python]\n",
      "CENTER        string[python]\n",
      "CENTERTYPE    string[python]\n",
      "DIST_FR              Float64\n",
      "DIST_LR              Float64\n",
      "DIST_BRT             Float64\n",
      "DIST_FWYE            Float64\n",
      "DIST_PARK            Float64\n",
      "DIST_TRAIL           Float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "hui_df['UNIT_ID'] = hui_df['UNIT_ID'].astype('int32')\n",
    "hui_df['UNIT_COUNT'] = hui_df['UNIT_COUNT'].astype('int32')\n",
    "hui_df['APX_BLT_YR'] = hui_df['APX_BLT_YR'].astype('Int32')\n",
    "print(hui_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\Housing-Unit-Inventory-Explorer\\\\python\\\\Outputs\\\\hui_for_web2.gdb\\\\hui_web_version'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export polygon file\n",
    "hui_df.spatial.to_featureclass(location=os.path.join(gdb2, 'hui_web_version'), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Thursday, May 22, 2025 6:14:04 PM<br>Succeeded at Thursday, May 22, 2025 6:14:31 PM (Elapsed Time: 27.09 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\hui_for_web2.gdb\\\\hui_pts_web_version'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export points file\n",
    "arcpy.management.FeatureToPoint(os.path.join(gdb2, 'hui_web_version'), os.path.join(gdb2, 'hui_pts_web_version'), \"INSIDE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 78.64 minutes\n"
     ]
    }
   ],
   "source": [
    "# track run time\n",
    "end = time.perf_counter()\n",
    "elapsed_minutes = (end - start) / 60\n",
    "print(f\"Elapsed time: {elapsed_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
